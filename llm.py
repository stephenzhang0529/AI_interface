import streamlit as st
import requests
import json
import os
import authenticator as auth
import database # Import the database module

# --- Configuration ---
DEEPSEEK_API_URL = "https://api.siliconflow.cn/v1/chat/completions"
DEEPSEEK_API_KEY = os.environ["API_KEY"]
# CHAT_HISTORY_FILE = 'chat_history.json' # No longer needed for file-based saving

# Mapping from user-friendly display names to actual model identifiers for the API
MODEL_PREFIX = "deepseek-ai/"
MODEL_OPTIONS_MAP = {
    "DeepSeek-R1": f"{MODEL_PREFIX}DeepSeek-R1",
    "DeepSeek-V3": f"{MODEL_PREFIX}DeepSeek-V3",  # As per original list
    "DeepSeek-R1-70B": f"{MODEL_PREFIX}DeepSeek-R1-Distill-Llama-70B",
    "DeepSeek-R1-14B": f"{MODEL_PREFIX}DeepSeek-R1-Distill-Qwen-14B",
}


# --- Helper Functions (removed file-based load/save, now use database) ---
# def load_chat_history():
#     if os.path.exists(CHAT_HISTORY_FILE):
#         try:
#             with open(CHAT_HISTORY_FILE, 'r', encoding='utf-8') as f:
#                 return json.load(f)
#         except json.JSONDecodeError:
#             st.error(f"Error reading chat history file '{CHAT_HISTORY_FILE}'. File might be corrupted.")
#             return []
#     return []


# def save_chat_history(messages):
#     try:
#         with open(CHAT_HISTORY_FILE, 'w', encoding='utf-8') as f:
#             json.dump(messages, f, ensure_ascii=False, indent=4)
#     except IOError as e:
#         st.error(f"Error saving chat history: {e}")


def asktoai(user_input, system_prompt_content, conversation_history, model_option, max_tokens_val, top_p_val):
    headers = {
        "Authorization": f"Bearer {DEEPSEEK_API_KEY}",
        "Content-Type": "application/json"
    }
    api_messages = []
    if system_prompt_content and system_prompt_content.strip():
        api_messages.append({"role": "system", "content": system_prompt_content})
    for i, msg_content in enumerate(conversation_history):
        role = "user" if i % 2 == 0 else "assistant"
        api_messages.append({"role": role, "content": msg_content})
    api_messages.append({"role": "user", "content": user_input})

    payload = {
        "model": model_option,  # This will now use the prefixed model name
        "messages": api_messages,
        "stream": False,
        "max_tokens": max_tokens_val,
        "stop": ["null"],
        "temperature": 0.7,
        "top_p": top_p_val,
        "top_k": 50,
        "frequency_penalty": 0.5,
        "n": 1,
        "response_format": {"type": "text"},
    }

    try:
        with st.spinner("AIæ­£åœ¨æ€è€ƒä¸­..."):
            response = requests.post(DEEPSEEK_API_URL, headers=headers, json=payload, timeout=120)
        response.raise_for_status()
        response_data = response.json()
        if response_data.get("choices") and len(response_data["choices"]) > 0 and response_data["choices"][0].get(
                "message"):
            ai_response = response_data["choices"][0]["message"]["content"]
            return ai_response.strip() if ai_response else "error: empty response from AI"
        else:
            st.error("APIå“åº”æ ¼å¼ä¸æ­£ç¡®æˆ–choicesä¸ºç©ºã€‚")
            st.json(response_data)
            return "error: API response format issue"
    except requests.exceptions.Timeout:
        st.error("APIè¯·æ±‚è¶…æ—¶ã€‚è¯·ç¨åå†è¯•æˆ–å¢åŠ è¶…æ—¶æ—¶é—´ã€‚")
        return "error: request timeout"
    except requests.exceptions.RequestException as e:
        st.error(f"APIè¯·æ±‚å¤±è´¥: {e}")
        if hasattr(e, 'response') and e.response is not None:
            st.error(f"æœåŠ¡å™¨å“åº”ç : {e.response.status_code}")
            st.text(f"é”™è¯¯è¯¦æƒ…: {e.response.text}")
            try:
                st.json(e.response.json())
            except json.JSONDecodeError:
                pass
        return "error: request failed"
    except Exception as e:
        st.error(f"å¤„ç†APIè¯·æ±‚æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
        return "error: unknown processing error"


# --- Streamlit App UI ---
st.set_page_config(page_title="ç™¾å®¶é¥­AI", layout="wide")
st.title("ç™¾å®¶é¥­AI")

# Check authentication status first
if not st.session_state.get("authenticated"):
    auth.show_login_page() # Redirect to login if not authenticated
    st.stop() # Stop further execution of this script until authenticated

# Retrieve current user's ID
# Assuming 'username' is stored in session_state after successful login
current_username = st.session_state.get('username')
current_user = database.get_user_by_username(current_username)
current_user_id = current_user['id'] if current_user else None

if not current_user_id:
    st.error("æ— æ³•è·å–å½“å‰ç”¨æˆ·ä¿¡æ¯ï¼Œè¯·å°è¯•é‡æ–°ç™»å½•ã€‚")
    st.stop()


# Sidebar for settings
with st.sidebar:
    st.header("âš™ï¸ è®¾ç½®")

    # Model selection
    display_model_names = list(MODEL_OPTIONS_MAP.keys())
    selected_display_name = st.selectbox(
        "é€‰æ‹©æ¨¡å‹:",
        options=display_model_names,
        index=0,
        placeholder="é€‰æ‹©ä¸€ä¸ªæ¨¡å‹...",
        key="model_select",  # This key associates with selected_display_name state
        help="é€‰æ‹©æ‚¨æƒ³ä½¿ç”¨çš„AIæ¨¡å‹ã€‚"
    )
    # The actual model identifier to be used in API calls
    model_selected = MODEL_OPTIONS_MAP[selected_display_name]

    st.subheader("ğŸ“ System Prompt")
    system_prompt_input = st.text_area(
        "è®¾å®šAIçš„è§’è‰²æˆ–è¡Œä¸ºæŒ‡ä»¤:",
        placeholder="ä¾‹å¦‚ï¼šä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„AIåŠ©æ‰‹ï¼Œè¯·ç”¨ä¸­æ–‡å›ç­”æ‰€æœ‰é—®é¢˜ã€‚",
        height=120,
        key="system_prompt_area",
        help="åœ¨è¿™é‡Œè¾“å…¥å…¨å±€æŒ‡ä»¤ï¼ŒAIä¼šåœ¨æ¯æ¬¡å¯¹è¯æ—¶å‚è€ƒè¿™ä¸ªæç¤ºã€‚"
    )

    st.subheader("ğŸ› ï¸ å‚æ•°è°ƒæ•´")
    max_token_val = st.slider(
        "Max Tokens:",
        min_value=50, max_value=8192, value=2048, step=64, key="max_token_slider",
        help="AIå›å¤çš„æœ€å¤§é•¿åº¦ï¼ˆä»¥tokensè®¡ç®—ï¼‰ã€‚"
    )
    top_p_slider_val = st.slider(
        "Temperature:",
        min_value=0.0, max_value=1.0, value=0.7, step=0.01, key="top_p_slider",
        help="æ§åˆ¶è¾“å‡ºæ–‡æœ¬çš„éšæœºæ€§ã€‚è¾ƒä½çš„å€¼ä½¿è¾“å‡ºæ›´é›†ä¸­å’Œç¡®å®šæ€§ï¼Œè¾ƒé«˜çš„å€¼æ›´å¤šæ ·åŒ–ã€‚\n(åŸä»£ç ä¸­æ­¤æ»‘å—åä¸ºTemperatureï¼Œä½†å®é™…æ§åˆ¶APIçš„top_på‚æ•°ï¼Œtemperatureå‚æ•°å›ºå®šä¸º0.7)"
    )


if 'messages' not in st.session_state:
    if not st.session_state.get('messages'):
        st.session_state.messages = []
# Initialize session state for the current model in use for saving
if 'current_session_model' not in st.session_state:
    st.session_state.current_session_model = model_selected


for i, msg_content in enumerate(st.session_state.messages):
    role_name = "human" if i % 2 == 0 else "ai"
    with st.chat_message(name=role_name):
        st.markdown(msg_content)

user_chat_input = st.chat_input("æ‚¨å¥½ï¼Œè¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„ï¼Ÿ")

if user_chat_input:
    # Update the model used for the current session if it changed
    # Only if there are no messages yet, or if we decide to allow changing mid-session
    # For now, let's assume if a new chat input comes, we use the currently selected model
    if not st.session_state.messages or st.session_state.current_session_model != model_selected:
        st.session_state.current_session_model = model_selected

    with st.chat_message("human"):
        st.markdown(user_chat_input)
    history_for_api = list(st.session_state.messages)
    st.session_state.messages.append(user_chat_input)

    ai_response = asktoai(
        user_input=user_chat_input,
        system_prompt_content=system_prompt_input,
        conversation_history=history_for_api,
        model_option=model_selected,  # Use the derived model_selected here
        max_tokens_val=max_token_val,
        top_p_val=top_p_slider_val
    )

    if ai_response and not ai_response.startswith("error:"):
        with st.chat_message("ai"):
            st.markdown(ai_response)
        st.session_state.messages.append(ai_response)
    else:
        if st.session_state.messages and st.session_state.messages[-1] == user_chat_input:
            st.session_state.messages.pop()

st.markdown("---", unsafe_allow_html=True)
if st.button("ğŸ’¾ ä¿å­˜èŠå¤©è®°å½•å¹¶å¼€å§‹æ–°å¯¹è¯", help="ä¿å­˜å½“å‰å¯¹è¯åˆ°æœ¬åœ°æ–‡ä»¶ï¼Œå¹¶æ¸…ç©ºå½“å‰èŠå¤©ç•Œé¢ã€‚"):
    if st.session_state.messages:
        # Pass the current_user_id, the model used for this session, and messages to the database function
        success = database.save_chat_session(current_user_id, st.session_state.current_session_model, st.session_state.messages)
        if success:
            st.success("èŠå¤©è®°å½•å·²ä¿å­˜åˆ°æ•°æ®åº“ï¼å°†å¼€å§‹æ–°çš„å¯¹è¯ã€‚")
            st.session_state.messages = []
            st.session_state.current_session_model = model_selected # Reset model for new session
            st.rerun()
        else:
            st.error("ä¿å­˜èŠå¤©è®°å½•åˆ°æ•°æ®åº“å¤±è´¥ã€‚")
    else:
        st.info("å½“å‰æ²¡æœ‰èŠå¤©è®°å½•å¯ä¿å­˜ã€‚")